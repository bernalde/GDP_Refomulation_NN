# Tuning hyper-parameters for precision

Best parameters set found on development set:

{'activation': 'relu', 'hidden_layer_sizes': [3, 5, 6]}

Grid scores on development set:

0.450 (+/-0.256) for {'activation': 'logistic', 'hidden_layer_sizes': [6, 6, 6]}
0.376 (+/-0.000) for {'activation': 'logistic', 'hidden_layer_sizes': [3, 3, 3]}
0.545 (+/-0.343) for {'activation': 'logistic', 'hidden_layer_sizes': [5, 5, 5]}
0.745 (+/-0.095) for {'activation': 'logistic', 'hidden_layer_sizes': [6, 6]}
0.540 (+/-0.331) for {'activation': 'logistic', 'hidden_layer_sizes': [5, 5]}
0.540 (+/-0.331) for {'activation': 'logistic', 'hidden_layer_sizes': [3, 3]}
0.376 (+/-0.000) for {'activation': 'logistic', 'hidden_layer_sizes': [6, 5, 3]}
0.587 (+/-0.271) for {'activation': 'logistic', 'hidden_layer_sizes': [3, 5, 6]}
0.745 (+/-0.095) for {'activation': 'logistic', 'hidden_layer_sizes': [6, 5]}
0.745 (+/-0.095) for {'activation': 'logistic', 'hidden_layer_sizes': [6, 3]}
0.732 (+/-0.082) for {'activation': 'logistic', 'hidden_layer_sizes': [5, 6]}
0.745 (+/-0.095) for {'activation': 'logistic', 'hidden_layer_sizes': [3, 5]}
0.732 (+/-0.082) for {'activation': 'logistic', 'hidden_layer_sizes': [3, 6]}
0.745 (+/-0.095) for {'activation': 'logistic', 'hidden_layer_sizes': [5, 3]}
0.376 (+/-0.000) for {'activation': 'logistic', 'hidden_layer_sizes': [4, 4, 4]}
0.742 (+/-0.091) for {'activation': 'tanh', 'hidden_layer_sizes': [6, 6, 6]}
0.745 (+/-0.095) for {'activation': 'tanh', 'hidden_layer_sizes': [3, 3, 3]}
0.744 (+/-0.092) for {'activation': 'tanh', 'hidden_layer_sizes': [5, 5, 5]}
0.745 (+/-0.095) for {'activation': 'tanh', 'hidden_layer_sizes': [6, 6]}
0.745 (+/-0.095) for {'activation': 'tanh', 'hidden_layer_sizes': [5, 5]}
0.745 (+/-0.095) for {'activation': 'tanh', 'hidden_layer_sizes': [3, 3]}
0.744 (+/-0.093) for {'activation': 'tanh', 'hidden_layer_sizes': [6, 5, 3]}
0.745 (+/-0.095) for {'activation': 'tanh', 'hidden_layer_sizes': [3, 5, 6]}
0.745 (+/-0.095) for {'activation': 'tanh', 'hidden_layer_sizes': [6, 5]}
0.745 (+/-0.095) for {'activation': 'tanh', 'hidden_layer_sizes': [6, 3]}
0.745 (+/-0.095) for {'activation': 'tanh', 'hidden_layer_sizes': [5, 6]}
0.745 (+/-0.092) for {'activation': 'tanh', 'hidden_layer_sizes': [3, 5]}
0.745 (+/-0.095) for {'activation': 'tanh', 'hidden_layer_sizes': [3, 6]}
0.745 (+/-0.095) for {'activation': 'tanh', 'hidden_layer_sizes': [5, 3]}
0.742 (+/-0.090) for {'activation': 'tanh', 'hidden_layer_sizes': [4, 4, 4]}
0.742 (+/-0.091) for {'activation': 'relu', 'hidden_layer_sizes': [6, 6, 6]}
0.743 (+/-0.092) for {'activation': 'relu', 'hidden_layer_sizes': [3, 3, 3]}
0.745 (+/-0.098) for {'activation': 'relu', 'hidden_layer_sizes': [5, 5, 5]}
0.740 (+/-0.089) for {'activation': 'relu', 'hidden_layer_sizes': [6, 6]}
0.744 (+/-0.092) for {'activation': 'relu', 'hidden_layer_sizes': [5, 5]}
0.450 (+/-0.256) for {'activation': 'relu', 'hidden_layer_sizes': [3, 3]}
0.376 (+/-0.000) for {'activation': 'relu', 'hidden_layer_sizes': [6, 5, 3]}
0.746 (+/-0.095) for {'activation': 'relu', 'hidden_layer_sizes': [3, 5, 6]}
0.745 (+/-0.095) for {'activation': 'relu', 'hidden_layer_sizes': [6, 5]}
0.745 (+/-0.095) for {'activation': 'relu', 'hidden_layer_sizes': [6, 3]}
0.745 (+/-0.095) for {'activation': 'relu', 'hidden_layer_sizes': [5, 6]}
0.745 (+/-0.095) for {'activation': 'relu', 'hidden_layer_sizes': [3, 5]}
0.745 (+/-0.095) for {'activation': 'relu', 'hidden_layer_sizes': [3, 6]}
0.550 (+/-0.357) for {'activation': 'relu', 'hidden_layer_sizes': [5, 3]}
0.730 (+/-0.080) for {'activation': 'relu', 'hidden_layer_sizes': [4, 4, 4]}

Detailed classification report:

The model is trained on the full development set.
[[2094   87]
 [ 524  195]]
The scores are computed on the full evaluation set.

             precision    recall  f1-score   support

          0       0.81      0.97      0.88       936
          1       0.76      0.29      0.42       309

avg / total       0.80      0.80      0.77      1245

[[908  28]
 [219  90]]

# Tuning hyper-parameters for recall

Best parameters set found on development set:

{'activation': 'relu', 'hidden_layer_sizes': [4, 4, 4]}

Grid scores on development set:

0.520 (+/-0.069) for {'activation': 'logistic', 'hidden_layer_sizes': [6, 6, 6]}
0.500 (+/-0.000) for {'activation': 'logistic', 'hidden_layer_sizes': [3, 3, 3]}
0.542 (+/-0.085) for {'activation': 'logistic', 'hidden_layer_sizes': [5, 5, 5]}
0.616 (+/-0.048) for {'activation': 'logistic', 'hidden_layer_sizes': [6, 6]}
0.547 (+/-0.096) for {'activation': 'logistic', 'hidden_layer_sizes': [5, 5]}
0.547 (+/-0.096) for {'activation': 'logistic', 'hidden_layer_sizes': [3, 3]}
0.500 (+/-0.000) for {'activation': 'logistic', 'hidden_layer_sizes': [6, 5, 3]}
0.560 (+/-0.107) for {'activation': 'logistic', 'hidden_layer_sizes': [3, 5, 6]}
0.616 (+/-0.048) for {'activation': 'logistic', 'hidden_layer_sizes': [6, 5]}
0.616 (+/-0.048) for {'activation': 'logistic', 'hidden_layer_sizes': [6, 3]}
0.619 (+/-0.056) for {'activation': 'logistic', 'hidden_layer_sizes': [5, 6]}
0.616 (+/-0.048) for {'activation': 'logistic', 'hidden_layer_sizes': [3, 5]}
0.619 (+/-0.056) for {'activation': 'logistic', 'hidden_layer_sizes': [3, 6]}
0.616 (+/-0.048) for {'activation': 'logistic', 'hidden_layer_sizes': [5, 3]}
0.500 (+/-0.000) for {'activation': 'logistic', 'hidden_layer_sizes': [4, 4, 4]}
0.615 (+/-0.047) for {'activation': 'tanh', 'hidden_layer_sizes': [6, 6, 6]}
0.616 (+/-0.048) for {'activation': 'tanh', 'hidden_layer_sizes': [3, 3, 3]}
0.616 (+/-0.047) for {'activation': 'tanh', 'hidden_layer_sizes': [5, 5, 5]}
0.616 (+/-0.048) for {'activation': 'tanh', 'hidden_layer_sizes': [6, 6]}
0.616 (+/-0.048) for {'activation': 'tanh', 'hidden_layer_sizes': [5, 5]}
0.616 (+/-0.048) for {'activation': 'tanh', 'hidden_layer_sizes': [3, 3]}
0.615 (+/-0.048) for {'activation': 'tanh', 'hidden_layer_sizes': [6, 5, 3]}
0.616 (+/-0.048) for {'activation': 'tanh', 'hidden_layer_sizes': [3, 5, 6]}
0.616 (+/-0.048) for {'activation': 'tanh', 'hidden_layer_sizes': [6, 5]}
0.616 (+/-0.048) for {'activation': 'tanh', 'hidden_layer_sizes': [6, 3]}
0.616 (+/-0.048) for {'activation': 'tanh', 'hidden_layer_sizes': [5, 6]}
0.618 (+/-0.047) for {'activation': 'tanh', 'hidden_layer_sizes': [3, 5]}
0.616 (+/-0.048) for {'activation': 'tanh', 'hidden_layer_sizes': [3, 6]}
0.616 (+/-0.048) for {'activation': 'tanh', 'hidden_layer_sizes': [5, 3]}
0.616 (+/-0.046) for {'activation': 'tanh', 'hidden_layer_sizes': [4, 4, 4]}
0.615 (+/-0.047) for {'activation': 'relu', 'hidden_layer_sizes': [6, 6, 6]}
0.615 (+/-0.046) for {'activation': 'relu', 'hidden_layer_sizes': [3, 3, 3]}
0.616 (+/-0.048) for {'activation': 'relu', 'hidden_layer_sizes': [5, 5, 5]}
0.611 (+/-0.041) for {'activation': 'relu', 'hidden_layer_sizes': [6, 6]}
0.615 (+/-0.045) for {'activation': 'relu', 'hidden_layer_sizes': [5, 5]}
0.520 (+/-0.069) for {'activation': 'relu', 'hidden_layer_sizes': [3, 3]}
0.500 (+/-0.000) for {'activation': 'relu', 'hidden_layer_sizes': [6, 5, 3]}
0.616 (+/-0.048) for {'activation': 'relu', 'hidden_layer_sizes': [3, 5, 6]}
0.616 (+/-0.048) for {'activation': 'relu', 'hidden_layer_sizes': [6, 5]}
0.616 (+/-0.048) for {'activation': 'relu', 'hidden_layer_sizes': [6, 3]}
0.616 (+/-0.048) for {'activation': 'relu', 'hidden_layer_sizes': [5, 6]}
0.613 (+/-0.047) for {'activation': 'relu', 'hidden_layer_sizes': [3, 5]}
0.616 (+/-0.048) for {'activation': 'relu', 'hidden_layer_sizes': [3, 6]}
0.563 (+/-0.127) for {'activation': 'relu', 'hidden_layer_sizes': [5, 3]}
0.623 (+/-0.065) for {'activation': 'relu', 'hidden_layer_sizes': [4, 4, 4]}

Detailed classification report:

The model is trained on the full development set.
[[2092   89]
 [ 522  197]]
The scores are computed on the full evaluation set.

             precision    recall  f1-score   support

          0       0.81      0.97      0.88       936
          1       0.76      0.29      0.42       309

avg / total       0.80      0.80      0.77      1245

[[908  28]
 [219  90]]

# Tuning hyper-parameters for f1

Best parameters set found on development set:

{'activation': 'relu', 'hidden_layer_sizes': [4, 4, 4]}

Grid scores on development set:

0.468 (+/-0.134) for {'activation': 'logistic', 'hidden_layer_sizes': [6, 6, 6]}
0.429 (+/-0.000) for {'activation': 'logistic', 'hidden_layer_sizes': [3, 3, 3]}
0.510 (+/-0.161) for {'activation': 'logistic', 'hidden_layer_sizes': [5, 5, 5]}
0.631 (+/-0.063) for {'activation': 'logistic', 'hidden_layer_sizes': [6, 6]}
0.516 (+/-0.175) for {'activation': 'logistic', 'hidden_layer_sizes': [5, 5]}
0.516 (+/-0.175) for {'activation': 'logistic', 'hidden_layer_sizes': [3, 3]}
0.429 (+/-0.000) for {'activation': 'logistic', 'hidden_layer_sizes': [6, 5, 3]}
0.539 (+/-0.175) for {'activation': 'logistic', 'hidden_layer_sizes': [3, 5, 6]}
0.631 (+/-0.063) for {'activation': 'logistic', 'hidden_layer_sizes': [6, 5]}
0.631 (+/-0.063) for {'activation': 'logistic', 'hidden_layer_sizes': [6, 3]}
0.634 (+/-0.069) for {'activation': 'logistic', 'hidden_layer_sizes': [5, 6]}
0.631 (+/-0.063) for {'activation': 'logistic', 'hidden_layer_sizes': [3, 5]}
0.634 (+/-0.069) for {'activation': 'logistic', 'hidden_layer_sizes': [3, 6]}
0.631 (+/-0.063) for {'activation': 'logistic', 'hidden_layer_sizes': [5, 3]}
0.429 (+/-0.000) for {'activation': 'logistic', 'hidden_layer_sizes': [4, 4, 4]}
0.630 (+/-0.061) for {'activation': 'tanh', 'hidden_layer_sizes': [6, 6, 6]}
0.631 (+/-0.063) for {'activation': 'tanh', 'hidden_layer_sizes': [3, 3, 3]}
0.632 (+/-0.061) for {'activation': 'tanh', 'hidden_layer_sizes': [5, 5, 5]}
0.631 (+/-0.063) for {'activation': 'tanh', 'hidden_layer_sizes': [6, 6]}
0.631 (+/-0.063) for {'activation': 'tanh', 'hidden_layer_sizes': [5, 5]}
0.631 (+/-0.063) for {'activation': 'tanh', 'hidden_layer_sizes': [3, 3]}
0.631 (+/-0.062) for {'activation': 'tanh', 'hidden_layer_sizes': [6, 5, 3]}
0.631 (+/-0.063) for {'activation': 'tanh', 'hidden_layer_sizes': [3, 5, 6]}
0.631 (+/-0.063) for {'activation': 'tanh', 'hidden_layer_sizes': [6, 5]}
0.631 (+/-0.063) for {'activation': 'tanh', 'hidden_layer_sizes': [6, 3]}
0.631 (+/-0.063) for {'activation': 'tanh', 'hidden_layer_sizes': [5, 6]}
0.634 (+/-0.061) for {'activation': 'tanh', 'hidden_layer_sizes': [3, 5]}
0.631 (+/-0.063) for {'activation': 'tanh', 'hidden_layer_sizes': [3, 6]}
0.631 (+/-0.063) for {'activation': 'tanh', 'hidden_layer_sizes': [5, 3]}
0.631 (+/-0.059) for {'activation': 'tanh', 'hidden_layer_sizes': [4, 4, 4]}
0.630 (+/-0.061) for {'activation': 'relu', 'hidden_layer_sizes': [6, 6, 6]}
0.630 (+/-0.060) for {'activation': 'relu', 'hidden_layer_sizes': [3, 3, 3]}
0.632 (+/-0.063) for {'activation': 'relu', 'hidden_layer_sizes': [5, 5, 5]}
0.625 (+/-0.053) for {'activation': 'relu', 'hidden_layer_sizes': [6, 6]}
0.631 (+/-0.058) for {'activation': 'relu', 'hidden_layer_sizes': [5, 5]}
0.468 (+/-0.134) for {'activation': 'relu', 'hidden_layer_sizes': [3, 3]}
0.429 (+/-0.000) for {'activation': 'relu', 'hidden_layer_sizes': [6, 5, 3]}
0.632 (+/-0.062) for {'activation': 'relu', 'hidden_layer_sizes': [3, 5, 6]}
0.631 (+/-0.063) for {'activation': 'relu', 'hidden_layer_sizes': [6, 5]}
0.631 (+/-0.063) for {'activation': 'relu', 'hidden_layer_sizes': [6, 3]}
0.631 (+/-0.063) for {'activation': 'relu', 'hidden_layer_sizes': [5, 6]}
0.628 (+/-0.061) for {'activation': 'relu', 'hidden_layer_sizes': [3, 5]}
0.631 (+/-0.063) for {'activation': 'relu', 'hidden_layer_sizes': [3, 6]}
0.536 (+/-0.214) for {'activation': 'relu', 'hidden_layer_sizes': [5, 3]}
0.639 (+/-0.078) for {'activation': 'relu', 'hidden_layer_sizes': [4, 4, 4]}

Detailed classification report:

The model is trained on the full development set.
[[2092   89]
 [ 522  197]]
The scores are computed on the full evaluation set.

             precision    recall  f1-score   support

          0       0.81      0.97      0.88       936
          1       0.76      0.29      0.42       309

avg / total       0.80      0.80      0.77      1245

[[908  28]
 [219  90]]

